{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MuRIL_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8kKq7Vcao1kXkOSIEaFNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi03071991/MuRIL_finetuning/blob/main/MuRIL_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmQuuzzJmG2g",
        "outputId": "927d6ab5-90e6-4913-d68e-3432ae49ec90"
      },
      "source": [
        "!pip install gpustat"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.7)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat) (5.4.8)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjrW4eMJmRW7",
        "outputId": "075167a8-4850-4150-f46b-5a5dcfaec7d5"
      },
      "source": [
        "!gpustat"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37m3257e0e60aac       \u001b[m  Fri Dec 18 18:07:48 2020  \u001b[1m\u001b[30m418.67\u001b[m\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla T4        \u001b[m |\u001b[1m\u001b[31m 55'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m15079\u001b[m MB |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEJ8IXkmTes",
        "outputId": "72cdffae-5581-496d-8952-f3060369990d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hifvghb-mfeg",
        "outputId": "c22483eb-65dd-49d7-ea42-55f698d9118c"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/MuRIL')\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/MuRIL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjNwvRhbmfin",
        "outputId": "f202a7bd-8544-4dc0-b85d-143b835dbaaa"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.7)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwJ7igw4mfgt",
        "outputId": "57f0f82e-157e-4ae0-e5cf-bbc734f1655f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from tensorflow.keras.models import  Model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from sklearn import preprocessing\n",
        "from bert import bert_tokenization\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.4.0\n",
            "Hub version:  0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QixDBKKoESF"
      },
      "source": [
        "# Load train and val datasets\n",
        "df_train = pd.read_csv('tamil_train.tsv', sep = \"\\t\")\n",
        "df_val = pd.read_csv('tamil_dev.tsv', sep = \"\\t\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEXVtLY4zKXA",
        "outputId": "865fe230-df84-493d-a94a-fddf880498bd"
      },
      "source": [
        "# Columns\n",
        "df_train.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'category'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW-PO8F8p4HA",
        "outputId": "3e2aa8da-76e8-45a2-f39a-915b387d4b73"
      },
      "source": [
        "# Prepare input text and one hot encoded labels for train and validation sets\n",
        "\n",
        "unique_labels = list(np.unique(df_train[\"category\"]))\n",
        "\n",
        "train_x = df_train[\"text\"].values\n",
        "train_y = df_train[\"category\"].values\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "train_y = le.fit_transform(train_y)\n",
        "train_y = tf.keras.utils.to_categorical(train_y, num_classes=len(unique_labels), dtype='float32')\n",
        "\n",
        "val_x = df_val[\"text\"].values\n",
        "val_y = df_val[\"category\"].values\n",
        "\n",
        "val_y = le.fit_transform(val_y)\n",
        "val_y = tf.keras.utils.to_categorical(val_y, num_classes=len(unique_labels), dtype='float32')\n",
        "\n",
        "\n",
        "print(\"number of unique labels\", len(unique_labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of unique labels 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUD20x5Oqzgp",
        "outputId": "0c46afe8-05df-4ba5-d3f4-44fd59ef3608"
      },
      "source": [
        "# Check unique labels\n",
        "unique_labels"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mixed_feelings ', 'Negative ', 'Positive ', 'not-Tamil ', 'unknown_state ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEHX4WgmnIkM"
      },
      "source": [
        "# Function to create input_ids\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "# Function to create attention masks\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create segment ids\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create input_ids, attention_masks, segment_ids for sample\n",
        "def create_single_input(sentence,MAX_LEN, MAX_SEQ_LEN):\n",
        "  \n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "  \n",
        "  stokens = stokens[:MAX_LEN]\n",
        "  \n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        " \n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids,masks,segments\n",
        "\n",
        "def create_input_array(sentences, MAX_SEQ_LEN):\n",
        "\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "  \n",
        "    ids,masks,segments=create_single_input(sentence,MAX_SEQ_LEN-2, MAX_SEQ_LEN)\n",
        "\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8AmiWuknTKL"
      },
      "source": [
        "# MuRIL model layer\n",
        "muril_layer = hub.KerasLayer(\"https://tfhub.dev/google/MuRIL/1\", trainable=True)\n",
        "\n",
        "# Create tokenizer\n",
        "vocab_file = muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = muril_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqjXUqturNk",
        "outputId": "289dd609-7759-4f52-f943-981516eb66ce"
      },
      "source": [
        "# Create input_ids, attention_masks, segment_ids for training and validation sets with max_seq_len as 128\n",
        "max_seq_len = 128\n",
        "train_x = create_input_array(train_x, max_seq_len)\n",
        "val_x = create_input_array(val_x, max_seq_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11335/11335 [00:01<00:00, 6271.16it/s]\n",
            "100%|██████████| 1260/1260 [00:00<00:00, 5982.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtImk-2eqn4a"
      },
      "source": [
        "# Define model function - compile and fit\n",
        "def model_fit(train_x, train_y, val_x, val_y, max_seq_length, num_epochs, muril_layer):\n",
        "\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "  \n",
        "  outputs = muril_layer(dict(input_word_ids = input_word_ids, input_mask = input_mask, input_type_ids = segment_ids))\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.2)(outputs[\"pooled_output\"]) # take pooled output layer\n",
        "  final_output = tf.keras.layers.Dense(5, activation=\"softmax\", name=\"dense_output\")(x)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=[input_word_ids, input_mask, segment_ids], outputs=final_output)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "  model.fit(train_x, train_y, epochs = num_epochs, batch_size = 32, validation_data = (val_x, val_y), shuffle = True)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ_Jv6sulcq",
        "outputId": "46a72151-7ba2-4bb5-d224-9052eb8ffab6"
      },
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "# Get the model object\n",
        "model = model_fit(train_x, train_y, val_x, val_y, max_seq_len, num_epochs, muril_layer)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "355/355 [==============================] - 350s 954ms/step - loss: 1.0874 - accuracy: 0.6662 - val_loss: 1.0215 - val_accuracy: 0.6802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Y7dCzfrDJT"
      },
      "source": [
        "# Make predictions\n",
        "preds = model.predict(val_x)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}